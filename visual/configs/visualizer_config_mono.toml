[io]
dataset_folder = "<datasets_folder_path>" # the main folder holds datasets
nice_tool_input_folder = "<output_folder_path>/nicetoolbox_input/<dataset_name>_<session_ID>_<sequence_ID>" # raw_processed input data
experiment_folder = "<output_folder_path>/experiments/20240719_communication_mono" # NICE Toolbox output
experiment_video_folder = "<experiment_folder>/<video_name>" # NICE Toolbox output folder for the selected video. Media part visualizes 1 video per session.
experiment_video_component = "<experiment_folder>/<video_name>/<component_name>" # NICE Toolbox output folder for the selected method (new name will be component) inside the video output folder

[media]
dataset_name = 'communication_mono' # current options: 'dyadic_communication', 'mpi_inf_3dhp' # each Media session shows one video results. Each video belongs a dataset
video_name = 'communication_mono_day_1_s0_l30' # each Media session shows one video results
multi_view = false # set false if you don't have multiple cameras

[media.visualize]
components = ["body_joints", "hand_joints", "face_landmarks", "gaze_individual", "kinematics", "proximity"]
camera_position = false # set true if want to visuailize camera position -- requires extrinsic information of the camera
start_frame = 0
end_frame = -1  # -1 means process until the end of the video, if you want to stop before, write the frame number.
visualize_interval = 1  # 1 means visualize every frame; change the parameter if you want to visualize every x frames

###### Setup Rerun Display Windows #####
### You can configure which data will be shown in which rerun window
### by changing the media.component.canvas items
### The keys, i.e., '3d' or '2d_interpolated', are the name of the data provided by that component.
### The lists define which canvases (rerun windows) will show this data:
### '3D_Canvas': the data will be visualised in 3D canvas. It can be created only for multi-view datasets. (don't change the canvas's name)
### cameras: the data will be visualized on that camera image. The name of camera has to be same as the camera folder (alsogiven in dataset_properties.toml)
### metrics - shows the data on plot
### empty list: the data will not visualized

### algorithms parameter under media.component define which algorithms will be displayed.
## In case there are multiple algorithms, such as hrnetw48 and vitpose in body_joints component,
## you can define which algorithm results will be shown.
## type both algorithm names if you want to see both of them.

# Component: gaze individual
[media.gaze_individual]
algorithms = ['xgaze_3cams']

[media.gaze_individual.canvas]
3d = ["<cam_front>"]## value options: [3D_Canvas], [3D_Canvas, camera names], [camera names], []
## -- Note: Delete '3D_Canvas' if you don't have a multi-view setup.

[media.gaze_individual.appearance]
colors = [[0,150, 90]]
radii = {'3d'= 0.01, 'camera_view'= 4}

# Component: gaze interaction
[media.gaze_interaction]
algorithms = ['gaze_distance']

[media.gaze_interaction.canvas]
#gaze_look_at_3d = ["<cam_front>"]## value options: [3D_Canvas], [3D_Canvas, camera names], [camera names], []
gaze_look_at_2d = ["<cam_front>"] ## use data key gaze+look_at_2d if you don't have a multi-view setup.

[media.gaze_interaction.appearance]
colors = [[[0,221, 22], [247, 13, 26]]] #vivid mala.. -green #vivid red -  [57,255,18] #neon green
radii = {}

# Component: body joints
[media.body_joints]
algorithms = ['vitpose', 'hrnetw48']

[media.body_joints.canvas]
3d = [] ## value options: 3D_Canvas, [] -- Note: set as [] if you don't have a multi-view setup.
2d_interpolated = ["<cam_front>"]  ##key options: 2d, 2d_interpolated, 2d_filtered ##value options: [camera names]

[media.body_joints.appearance]
colors = [[0, 191, 255], [200, 200, 200]]
radii = {'3d'= 0.01, 'camera_view'= 4}

# Component: hand joints
[media.hand_joints]
algorithms = ['hrnetw48']

[media.hand_joints.canvas]
3d = [] ## value options: 3D_Canvas, [] -- Note: set as [] if you don't have a multi-view setup.
2d_interpolated = ["<cam_front>"]  ##key options: 2d, 2d_interpolated, 2d_filtered ##value options: [camera names]

[media.hand_joints.appearance]
colors = [[255, 69, 0]]  # orange #alternative 255, 165, 0
radii = {'3d'= 0.006, 'camera_view'= 2}


# Component: face landmarks
[media.face_landmarks]
algorithms = ['hrnetw48']

[media.face_landmarks.canvas]
3d = [] ## value options: 3D_Canvas, [] -- Note: set as [] if you don't have a multi-view setup.
2d_interpolated = ["<cam_front>"]  ##key options: 2d, 2d_interpolated, 2d_filtered ##value options: [camera names]

[media.face_landmarks.appearance]
colors =  [[170,171,69]] #[255,255,4] yellow =- green j. [77, 188, 139]
radii = {'3d'= 0.01, 'camera_view'= 4}


# Component: kinematics
[media.kinematics]
algorithms = ['velocity_body']

[media.kinematics.canvas]
#velocity_body_3d = ["metric_velocity"] # if don't have multi-view, use velocity_body_2d
velocity_body_2d = ["metric_velocity"]

[media.kinematics.joints] ## visualize the mean velocity for the given bodyparts.
"head" = ["nose","left_eye","right_eye","left_ear","right_ear"]
"upper_body" = ["left_shoulder","right_shoulder","left_elbow", "right_elbow", "left_wrist", "right_wrist"]  # Indices of keypoints belonging to the upper body
"lower_body" = ["left_hip", "right_hip", "left_knee", "right_knee", "left_ankle", "right_ankle"]


# Component: proximity
[media.proximity]
algorithms = ['body_distance']

[media.proximity.canvas]
body_distance_3d = [] ## value options: 3D_Canvas, [] -- Note: set as [] if you don't have a multi-view setup.
body_distance_2d = ["<cam_front>"] ## value options: [camera nanes]

[media.proximity.appearance]
colors = [[153,50,204]]
radii = {'3d'= 0.008, 'camera_view'= 3}





