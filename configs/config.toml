# This config supports using placeholders.
# options are <git_hash> <commit_message> <me> <today> <yyyymmdd> <time> <pwd>
# and all keys from your local 'machine_specific_paths.toml'

git_hash = "<git_hash>"
# the inout video is processed into 'frames', 'segments' and 'snippets'
video_length = 2010  # in frames, relevant for all
video_start = 2700  # in frames, relevant for all
video_skip_frames = false  # relevant for frames only
annotation_interval = 2  # in seconds, length of segments

[io]
PIS_ID = "PIS_ID_04"
video_folder = "<pis_folder_path>/<PIS_ID>/IOI/compressed_25/withAudio"
calibration_file = "<pis_folder_path>/<PIS_ID>/Calibration/rescaled25/camera_params_calibio_2020-08-12.json"
process_data_to = "data_folder"  # options are 'data_folder' and 'tmp_folder'
data_folder = "<pis_folder_path>/raw_processed/isa_tool_input/<PIS_ID>"
tmp_folder = "<pis_folder_path>/experiments/tmp"
out_folder = "<pis_folder_path>/experiments/<yyyymmdd>"
method_out_folder = "<out_folder>/<method_name>/method_output"
method_visualization_folder = "<out_folder>/<method_name>/visualization"
method_additional_output_folder = "<out_folder>/<method_name>/additional_output"
method_tmp_folder = "<tmp_folder>/<method_name>"
method_final_result_folder = "<out_folder>/<method_name>"
code_folder = "<pwd>"

[methods]
names = ["mmpose", "xgaze_3cams", "emoca"]

[methods.nodding_pigeon]
input_data_format = "segments"
camera_names = ["cam1", "cam2"]
env_name = "venv:env"

[methods.ethXgaze]
input_data_format = "frames"
camera_names = ["cam1", "cam2"]
shape_predictor_filename = "<methods_folder_path>/ethXgaze/ethXgaze/modules/shape_predictor_68_face_landmarks.dat"
face_model_filename = "<methods_folder_path>/ethXgaze/ethXgaze/face_model.txt"
pretrained_model_filename = "<methods_folder_path>/ethXgaze/ethXgaze/ckpt/epoch_24_ckpt.pth.tar"

[methods.xgaze_3cams]
input_data_format = "frames"
camera_names = ["cam1", "cam2", "cam3", "cam4"]
env_name = "venv:env"
shape_predictor_filename = "<pwd>/third_party/xgaze_3cams/xgaze_3cams/shape_predictor_68_face_landmarks.dat"
face_model_filename = "<pwd>/third_party/xgaze_3cams/xgaze_3cams/face_model.txt"
pretrained_model_filename = "<methods_folder_path>/ethXgaze/ethXgaze/ckpt/epoch_24_ckpt.pth.tar"
face_detector_filename = "<pwd>/third_party/xgaze_3cams/xgaze_3cams/mmod_human_face_detector.dat"

[methods.mmpose]
input_data_format = "frames"
camera_names = ["cam3", "cam4"]
algorithm = "hrnetw48"
env_name = "conda:openmmlab"
multi_person = true
save_images = true
resolution = [1000, 700] # ToDo - after implement bbox intersection calculation, get rid of this

[methods.mmpose.hrnetw48]
pose_config = "td-hm_hrnet-w48_8xb32-210e_coco-wholebody-384x288"
pose_checkpoint = "https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w48_coco_wholebody_384x288_dark-f5726563_20200918.pth"
detection_config = "./third_party/mmpose/configs/faster_rcnn_r50_fpn_coco.py"
detection_checkpoint = "./third_party/mmpose/configs/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth"
keypoint_mapping = "coco_wholebody"
min_detection_confidence = 0.5

[methods.emoca]
input_data_format = "frames"
camera_names = ["cam1", "cam2"]
camera_descr = ["personL", "personR"]
env_name = "venv:env"

[features]
names = ["kinematics", "proximity", "leaning"]

[features.kinematics]
input_detector_names = ["mmpose_hrnetw48"]

[features.proximity]
used_keypoints = ["nose"] # if the list is more than one keypoint, the midpoint
input_detector_names = ["mmpose_hrnetw48"]

[features.leaning]
used_keypoints = [["left_shoulder", "right_shoulder"], ["left_hip", "right_hip"], ["left_knee", "right_knee"]]
input_detector_name = "mmpose"
input_algorithm_name = "hrnetw48"

[features.gazeDistance]
input_detector_names = ["xgaze_3cams", "mmpose_hrnetw48"]
keypoint_mapping = "coco_wholebody"
