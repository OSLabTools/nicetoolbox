# This config supports using placeholders.
# options are <git_hash> <commit_message> <me> <today> <yyyymmdd> <time> <pwd>
# and all keys from your local 'machine_specific_paths.toml'

git_hash = "<git_hash>"
# the inout video is processed into 'frames', 'segments' and 'snippets'
video_length = 180  # in frames, relevant for all
video_start = 60  # in frames, relevant for all
video_skip_frames = 10  # relevant for frames only
annotation_interval = 1  # in seconds, length of segments



[io]
PIS_ID = "PIS_ID_000"
video_folder = "<pis_folder_path>/<PIS_ID>/IOI/compressed_25/withAudio"
calibration_file = "<pis_folder_path>/<PIS_ID>/Calibration/rescaled25/camera_params_calibio_2020-08-11.json"
process_data_to = "data_folder"  # options are 'data_folder' and 'tmp_folder'
data_folder = "<pis_folder_path>/raw_processed/isa_tool_input/<PIS_ID>"
tmp_folder = "<pis_folder_path>/experiments/tmp"
out_folder = "<pis_folder_path>/experiments/<yyyymmdd>"
method_out_folder = "<out_folder>/<method_name>/method_output"
method_visualization_folder = "<out_folder>/<method_name>/visualization"
method_additional_output_folder = "<out_folder>/<method_name>/additional_output"
method_tmp_folder = "<tmp_folder>/<method_name>"
method_final_result_folder = "<out_folder>/<method_name>"
code_folder = "<pwd>"

[methods]
names = ["mmpose"]

[methods.nodding_pigeon]
input_data_format = "segments"
camera_names = ["cam1", "cam2"]

[methods.ethXgaze]
input_data_format = "frames"
camera_names = ["cam1", "cam2"]
shape_predictor_filename = "<methods_folder_path>/ethXgaze/ethXgaze/modules/shape_predictor_68_face_landmarks.dat"
face_model_filename = "<methods_folder_path>/ethXgaze/ethXgaze/face_model.txt"
pretrained_model_filename = "<methods_folder_path>/ethXgaze/ethXgaze/ckpt/epoch_24_ckpt.pth.tar"

[methods.xgaze_3cams]
input_data_format = "frames"
camera_names = ["cam1", "cam2", "cam3", "cam4"]
env_name = "venv:env"
shape_predictor_filename = "<pwd>/third_party/xgaze_3cams/xgaze_3cams/shape_predictor_68_face_landmarks.dat"
face_model_filename = "<pwd>/third_party/xgaze_3cams/xgaze_3cams/face_model.txt"
pretrained_model_filename = "<methods_folder_path>/ethXgaze/ethXgaze/ckpt/epoch_24_ckpt.pth.tar"
face_detector_filename = "<pwd>/third_party/xgaze_3cams/xgaze_3cams/mmod_human_face_detector.dat"

[methods.mmpose]
input_data_format = "frames"
camera_names = ["cam3", "cam4"]
algorithm = "hrnetw48"
env_name = "conda:openmmlab"
multi_person = true
save_images = true
resolution = [1000, 700] # ToDo - after implement bbox intersection calculation, get rid of this

[methods.mmpose.hrnetw48]
pose_config = "td-hm_hrnet-w48_8xb32-210e_coco-wholebody-384x288"
pose_checkpoint = "https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w48_coco_wholebody_384x288_dark-f5726563_20200918.pth"
detection_config = "C:\\Users\\oslab\\Documents\\mmpose\\demo\\mmdetection_cfg\\faster_rcnn_r50_fpn_coco.py"
detection_checkpoint = "C:\\Users\\oslab\\Documents\\mmpose_0.27\\configs\\faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth"
keypoint_mapping = "coco_wholebody"
min_detection_confidence = 0.5

[features]
names = ["kinematics"]

[features.kinematics]
input_detector_name = "mmpose"
input_algorithm_name = "hrnetw48"
