# This config supports using placeholders.
# options are, e.g., all keys from your local 'machine_specific_paths.toml'

[algorithms.nodding_pigeon]
input_data_format = "segments"
camera_names = ["<cam_face1>", "<cam_face2>"]
env_name = "venv:env"

[algorithms.ethXgaze]
input_data_format = "frames"
camera_names = ["<cam_face1>", "<cam_face2>"]
shape_predictor_filename = "<assets>/xgaze_3cams/shape_predictor_68_face_landmarks.dat"
face_model_filename = "<assets>/xgaze_3cams/face_model.txt"
pretrained_model_filename = "<assets>/xgaze_3cams/epoch_24_ckpt.pth.tar"

[algorithms.xgaze_3cams]
input_data_format = "frames"
camera_names = ["<cam_face1>", "<cam_face2>", "<cam_top>", "<cam_front>"]
env_name = "venv:env"
shape_predictor_filename = "<assets>/xgaze_3cams/shape_predictor_68_face_landmarks.dat"
face_model_filename = "<assets>/xgaze_3cams/face_model.txt"
pretrained_model_filename = "<assets>/xgaze_3cams/epoch_24_ckpt.pth.tar"
face_detector_filename = "<assets>/xgaze_3cams/mmod_human_face_detector.dat"
log_frame_idx_interval = 10

[frameworks.mmpose]
input_data_format = "frames"
camera_names = ["<cam_top>", "<cam_front>"]
env_name = "conda:openmmlab"
multi_person = true
save_images = true
resolution = [1000, 700] # ToDo - after implement bbox intersection calculation, get rid of this
device = "cuda:0" #cuda:0
filtered = true
window_length = 5
polyorder = 2

[algorithms.hrnetw48]
framework = "mmpose"
pose_config = "td-hm_hrnet-w48_8xb32-210e_coco-wholebody-384x288"
pose_checkpoint = "<assets>/mmpose/configs/hrnet_w48_coco_wholebody_384x288_dark-f5726563_20200918.pth"
detection_config = "<assets>/mmpose/configs/faster_rcnn_r50_fpn_coco.py"
detection_checkpoint = "<assets>/mmpose/configs/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth"
keypoint_mapping = "coco_wholebody"
min_detection_confidence = 0.5

[algorithms.vitpose]
framework = "mmpose"
pose_config = "<assets>/mmpose/configs/td-hm_ViTPose-large_8xb64-210e_coco-256x192.py"
pose_checkpoint = "<assets>/mmpose/configs/td-hm_ViTPose-large_8xb64-210e_coco-256x192-53609f55_20230314.pth"
detection_config = "<assets>/mmpose/configs/faster_rcnn_r50_fpn_coco.py"
detection_checkpoint = "<assets>/mmpose/configs/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth"
keypoint_mapping = "coco_wholebody"
min_detection_confidence = 0.5


[algorithms.emoca]
input_data_format = "frames"
camera_names = ["<cam_face1>", "<cam_face2>"]
env_name = "venv:env"

[algorithms.active_speaker]
input_data_format = "snippets"
camera_names = ["<cam_top>", "<cam_front>"]
env_name = "venv:env"
ASC_model_weights = '<assets>/active_speaker/checkpoints/SPELL_audiovisual_feature_extraction_checkpoints/resnet18-tsm-aug.pth'
ASC_model_name = 'resnet18-tsm-aug'
# Two options for the edge connection mode.
# 'csi': Connect the nodes only with the same identities across the frames.
# 'cdi': Connect different identities across the frames.
graph_ec_mode = 'csi'
graph_time_span = 90
graph_tau = 0.9
evaluation_type = 'AVA_ASD'
GraViT_model = '<assets>/active_speaker/checkpoints/SPELL_ASD_default/ckpt_best.pt'
GraViT_config = '<assets>/active_speaker/checkpoints/SPELL_ASD_default/cfg.yaml'

# kinematics
[algorithms.velocity_body]
input_detector_names = [["body_joints", "hrnetw48"]]

# proximity
[algorithms.body_distance]
used_keypoints = ["nose"] # if the list is more than one keypoint, the midpoint
input_detector_names = [["body_joints", "hrnetw48"]]

# leaning
[algorithms.body_angle]
used_keypoints = [["left_shoulder", "right_shoulder"], ["left_hip", "right_hip"], ["left_knee", "right_knee"]]
input_detector_names = [["body_joints", "hrnetw48"]]

# gaze_interaction
[algorithms.gaze_distance]
input_detector_names = [["gaze_individual", "xgaze_3cams"], ["face_landmarks", "hrnetw48"]]
keypoint_mapping = "coco_wholebody"
